{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fpath = 'bikepgh_av_survey.csv' # fill the path to this file here\n",
    "data = pd.read_csv(data_fpath, index_col=0)\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose one of the text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_colnames = [\n",
    "    'interaction_details',\n",
    "    'positive_av_interaction',\n",
    "    'negative_av_interaction',\n",
    "    'other_av_regulations',\n",
    "    'elaborate_bikepgh_position',\n",
    "    'other_comments',\n",
    "                ]\n",
    "\n",
    "for colname in text_colnames:\n",
    "    print(f'{colname}: {data[colname].count()} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize (split text into words)\n",
    "This may seem trivial, but you'll want to detach punctuation from words, since \"person\" and \"person,\" aren't very different. And what about contractions such as \"I'm\"? Will you want to lowercase everything or is there some distinction between \"polish\" and \"Polish\" you'd want to preserve?\n",
    "\n",
    "You'll also want to think about \"stopwords\", function words such as \"the\" and \"and\", or \"or\" and \"that\". Counts for these words are often distracting to machine learning models, and they're often removed unless there may be important or meaningful variation in stopword usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "colname = # your selected column: 'interaction_details', 'other_av_regulations', 'other_comments', etc\n",
    "\n",
    "# Filter to non-empty rows for that column\n",
    "filtered_data = data[data[colname].map(lambda x: isinstance(x, str))].copy()\n",
    "print(f\"Filtered to {len(filtered_data)} entries\")\n",
    "\n",
    "# Get documents (each response will be a document)\n",
    "docs = filtered_data[colname].tolist()\n",
    "\n",
    "# Tokenize, remove stopwords, lowercase documents. Feel free to remove one of these steps and see what happens\n",
    "tokenized_docs = [list(tokenize(remove_stopwords(doc.lower()))) for doc in docs]\n",
    "\n",
    "print(len(tokenized_docs))\n",
    "tokenized_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many words per entry? How many total words for each text column?\n",
    "Now's a good time to use our tokenized documents to calculate some basic stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_words = sum([len(doc) for doc in tokenized_docs])\n",
    "avg_words = total_words/len(tokenized_docs)\n",
    "print('{}:'.format(colname))\n",
    "print('\\ttotal words: {}'.format(total_words))\n",
    "print('\\tavg words: {}'.format(avg_words))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features (words to numbers)\n",
    "One of the simplest ways to get documents into numeric format for machine learning is to simply count each unique word and treat each document as collection of these counts. For example, \"the dog barked loudly at the hat\" would become {the: 2, dog: 1, barked: 1, loudly: 1, at: 1, hat: 1}. Each unique word in the vocabulary is usually given an ID. Because order information is lost, this is referred to as the \"bag-of-words\" model of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "print(\"Found {} unique words\".format(len(dictionary.token2id)))\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs] # turn each document into a bag-of-words count\n",
    "corpus[1] # list of tuples (word_id, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run LDA\n",
    "Now let's let LDA find topics. Here you'll want to vary the number of topics and compare results in the interpretation later. Start with 5 or 10 and go up to as much as you feel comfortable trying to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "lda = LdaModel(corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "This is one of the tougher parts. You'll examine the words and documents given the highest probability for each topic and see if they make any sense (they might not). If they don't, go back and change the number of topics, change preprocessing (tokenization, etc), or throw up your hands and tell me how terrible topic modeling is :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top documents/topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_topics = lda.show_topics()\n",
    "word_topics # this will print in the format prob*\"word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top documents/topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_docs(lda, docs, n_docs=5):\n",
    "    document_topics = [lda.get_document_topics(bow) for bow in corpus]\n",
    "    lines = []\n",
    "    for topic_ind in range(lda.num_topics):\n",
    "        for doc_ind, dist in sorted(zip(list(range(len(document_topics))), document_topics), reverse=True, key=lambda x: abs(dict(x[1]).get(topic_ind, 0.0)))[:n_docs]:\n",
    "            topic_proportion = dict(dist).get(topic_ind, 0.0)\n",
    "            lines.append([topic_ind, word_topics[topic_ind][1], doc_ind, docs[doc_ind], topic_proportion])\n",
    "\n",
    "    return pd.DataFrame(lines, columns=['topic', 'topic_top_words', 'document_index', 'document', 'topic_proportion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "get_top_docs(lda, docs, n_docs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how distribution of other fields varies across topics\n",
    "Here, you can \"assign\" documents to their highest-ranking topic and see how other fields vary across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_topics = [lda.get_document_topics(bow) for bow in corpus]\n",
    "id2index = dict(zip(filtered_data.index, range(len(filtered_data))))\n",
    "\n",
    "# Assign top topics to docs\n",
    "filtered_data['top_topic'] = filtered_data.index.map(lambda x: sorted(document_topics[id2index[x]], key=lambda x: x[1], reverse=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topic =  # topic ID\n",
    "compared_column =  # Column to compare with: try 'feel_safe_avs' or others (print all with data.columns)\n",
    "topic_data = filtered_data[filtered_data['top_topic']==topic].copy()\n",
    "topic_data[compared_column].value_counts().sort_index().plot.bar().set_title(compared_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
