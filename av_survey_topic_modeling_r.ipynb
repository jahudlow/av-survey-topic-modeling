{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath <- '../av_survey_data/bikepgh_av_survey.csv' # fill the path to this file here\n",
    "text_col_classes = c(\n",
    "    'interaction_details'='character',\n",
    "    'positive_av_interaction'='character',\n",
    "    'negative_av_interaction'='character',\n",
    "    'other_av_regulations'='character',\n",
    "    'elaborate_bikepgh_position'='character',\n",
    "    'other_comments'='character'\n",
    "                )\n",
    "survey_data <- read.csv(data_fpath, colClasses=text_col_classes, na.strings=c(''))\n",
    "print(nrow(survey_data))\n",
    "print(sapply(survey_data, class))\n",
    "survey_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose one of the text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_colnames <- c(\n",
    "    'interaction_details',\n",
    "    'positive_av_interaction',\n",
    "    'negative_av_interaction',\n",
    "    'other_av_regulations',\n",
    "    'elaborate_bikepgh_position',\n",
    "    'other_comments'\n",
    "                )\n",
    "colname <-  # your selected column name goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-empty rows from that columns\n",
    "filtered_data <- subset(survey_data, !is.na(survey_data[colname]))\n",
    "nrow(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize (split text into words)\n",
    "This may seem trivial, but you'll want to detach punctuation from words, since \"person\" and \"person,\" aren't very different. And what about contractions such as \"I'm\"? Will you want to lowercase everything or is there some distinction between \"polish\" and \"Polish\" you'd want to preserve?\n",
    "\n",
    "You'll also want to think about \"stopwords\", function words such as \"the\" and \"and\", or \"or\" and \"that\". Counts for these words are often distracting to machine learning models, and they're often removed unless there may be important or meaningful variation in stopword usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(tidytext)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sapply(filtered_data, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data <- unnest_tokens(filtered_data, word, !!colname)\n",
    "nrow(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "tokenized_data <- anti_join(tokenized_data, get_stopwords())\n",
    "nrow(tokenized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features (words to numbers)\n",
    "One of the simplest ways to get documents into numeric format for machine learning is to simply count each unique word and treat each document as collection of these counts. For example, \"the dog barked loudly at the hat\" would become {the: 2, dog: 1, barked: 1, loudly: 1, at: 1, hat: 1}. Each unique word in the vocabulary is usually given an ID. Because order information is lost, this is referred to as the \"bag-of-words\" model of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make word counts\n",
    "word_counts <- tokenized_data %>% count(participant_id, word, sort=TRUE)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make document-term matrix\n",
    "\n",
    "dtm <- word_counts %>% cast_dtm(participant_id, word, n)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run LDA\n",
    "Now let's let LDA find topics. Here you'll want to vary the number of topics and compare results in the interpretation later. Start with 5 or 10 and go up to as much as you feel comfortable trying to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(topicmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda <- LDA(dtm, k=10, control=list(seed=9))\n",
    "lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "This is one of the tougher parts. You'll examine the words and documents given the highest probability for each topic and see if they make any sense (they might not). If they don't, go back and change the number of topics, change preprocessing (tokenization, etc), or throw up your hands and tell me how terrible topic modeling is :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top words/topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_topics <- tidy(lda, matrix='beta')\n",
    "\n",
    "top_topic_terms <- lda_topics %>% \n",
    "    group_by(topic) %>%\n",
    "    top_n(5, beta) %>%\n",
    "    ungroup() %>%\n",
    "    arrange(topic, -beta)\n",
    "\n",
    "top_topic_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top documents/topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_topics <- tidy(lda, matrix='gamma')\n",
    "\n",
    "top_topic_docs <- lda_topics %>% \n",
    "    group_by(topic) %>%\n",
    "    top_n(5, gamma) %>%\n",
    "    ungroup() %>%\n",
    "    arrange(topic, -gamma)\n",
    "\n",
    "top_topic_docs <- merge(top_topic_docs, filtered_data, by.x='document', by.y='participant_id', all.x=TRUE)[,c('document', 'topic', 'gamma', colname)]\n",
    "top_topic_docs <- top_topic_docs[order(top_topic_docs$topic),]\n",
    "top_topic_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how distribution of other fields varies across topics\n",
    "Here, you can \"assign\" documents to their highest-ranking topic and see how other fields vary across topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
